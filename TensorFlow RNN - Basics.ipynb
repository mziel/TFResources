{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of the data\n",
    "In this post, we’ll be building a no frills RNN that accepts a binary sequence X and uses it to predict a binary sequence Y. The sequences are constructed as follows:\n",
    "\n",
    "* **Input sequence** ($X$): At time step $t$, $X_t$ has a 50% chance of being 1 (and a 50% chance of being 0). E.g., $X$ might be $[1, 0, 0, 1, 1, 1 … ].$\n",
    "* **Output sequence** ($Y$): At time step $t$, $Y_t$ has a base 50% chance of being 1 (and a 50% base chance to be 0). The chance of $Y_t$ being 1 is increased by 50% (i.e., to 100%) if $X_{t−3}$ is 1, and decreased by 25% (i.e., to 25%) if $X_{t-8}$ is 1. If both are 1, the chance of $Y_t$ being 1 is 50% + 50% - 25% = 75%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected cross entropy loss if the model:\n",
      "- learns neither dependency: 0.6615632381579821\n",
      "- learns first dependency:   0.5191666997072094\n",
      "- learns both dependencies:  0.4544543674493905\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Expected cross entropy loss if the model:\")\n",
    "print(\"- learns neither dependency:\", -(0.625 * np.log(0.625) +\n",
    "                                      0.375 * np.log(0.375)))\n",
    "# Learns first dependency only ==> 0.51916669970720941\n",
    "print(\"- learns first dependency:  \",\n",
    "      -0.5 * (0.875 * np.log(0.875) + 0.125 * np.log(0.125))\n",
    "      -0.5 * (0.625 * np.log(0.625) + 0.375 * np.log(0.375)))\n",
    "print(\"- learns both dependencies: \", -0.50 * (0.75 * np.log(0.75) + 0.25 * np.log(0.25))\n",
    "      - 0.25 * (2 * 0.50 * np.log (0.50)) - 0.25 * (0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture\n",
    "\n",
    "The model will be as simple as possible: at time step $t$, for $t∈{0,1,…n}$ the model accepts a (one-hot) binary $X_t$ vector and a previous state vector, $S_{t−1}$, as inputs and produces a state vector, $S_t$, and a predicted probability distribution vector, $P_t$, for the (one-hot) binary vector $Y_t$.\n",
    "\n",
    "Formally, the model is:\n",
    "* $t=tanh(W(X_t @ S_{t−1})+b_s)$\n",
    "* $t=softmax(US_t+b_p)$\n",
    "\n",
    "here $@$ represents vector concatenation, $X_t∈R^2$ is a one-hot binary vector, $W∈R^{d×(2+d)}$, $b_s∈R^d$, $U∈R^{2×d}$, $b_p∈R^2$ and $d$ is the size of the state vector (I use $d=4$ below). At time step 0, $S−1$ (the initial state) is initialized as a vector of zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual pattern for dealing with very long sequences is therefore to “truncate” our backpropagation by backpropagating errors a maximum of n steps. We choose n as a hyperparameter to our model, keeping in mind the trade-off: higher n lets us capture longer term dependencies, but is more expensive computationally and memory-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Core implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzielinski/anaconda3/envs/keras/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/mzielinski/anaconda3/envs/keras/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder') # shape=(200, 5)\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes) #shape=(200, 5, 2)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1) #[shape=(200, 2), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\n",
    "This is very similar to the __call__ method on Tensorflow's BasicRNNCell. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L95\n",
    "\"\"\"\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding rnn_cells to graph\n",
    "\n",
    "This is a simplified version of the \"static_rnn\" function from Tensorflow's api. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41\n",
    "Note: In practice, using \"dynamic_rnn\" is a better choice that the \"static_rnn\":\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L390\n",
    "\"\"\"\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\n",
    "Losses is similar to the \"sequence_loss\"\n",
    "function from Tensorflow's API, except that here we are using a list of 2D tensors, instead of a 3D tensor. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py#L30\n",
    "\"\"\"\n",
    "\n",
    "#logits and predictions\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "# Turn our y placeholder into a list of labels\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.6580064356327057\n",
      "Average loss at step 200 for last 250 steps: 0.6015454721450806\n",
      "Average loss at step 300 for last 250 steps: 0.5779276531934738\n",
      "Average loss at step 400 for last 250 steps: 0.5234020724892616\n",
      "Average loss at step 500 for last 250 steps: 0.5211387008428574\n",
      "Average loss at step 600 for last 250 steps: 0.5208944416046143\n",
      "Average loss at step 700 for last 250 steps: 0.5179576647281646\n",
      "Average loss at step 800 for last 250 steps: 0.5190497723221779\n",
      "Average loss at step 900 for last 250 steps: 0.5216497442126274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12014d080>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the network very quickly learns to capture the first dependency (but not the second), and converges to the expected cross-entropy loss of 0.52.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow API (`static_rnn`)\n",
    "Translating our model to Tensorflow’s API is easy. We simply replace these two sections:\n",
    "```\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    ...\n",
    "def rnn_cell(rnn_input, state):\n",
    "    ...\n",
    "```\n",
    "```\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with\n",
    "```\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "Inputs\n",
    "\"\"\"\n",
    "\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "RNN\n",
    "\"\"\"\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\"\"\"\n",
    "\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.6223545253276825\n",
      "Average loss at step 200 for last 250 steps: 0.5226381602883339\n",
      "Average loss at step 300 for last 250 steps: 0.5195956349372863\n",
      "Average loss at step 400 for last 250 steps: 0.5214451411366463\n",
      "Average loss at step 500 for last 250 steps: 0.5186074489355087\n",
      "Average loss at step 600 for last 250 steps: 0.5219508638978004\n",
      "Average loss at step 700 for last 250 steps: 0.5199247208237648\n",
      "Average loss at step 800 for last 250 steps: 0.5210795599222183\n",
      "Average loss at step 900 for last 250 steps: 0.5230103918910026\n"
     ]
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two major downsides. \n",
    "* First, a graph composed in this way has to be **fixed length**, which means you’ll **have to rebuild the graph for different length signals, or pad them out with zeros**. Neither solution is great.\n",
    "\n",
    "* Second, **large graphs take much longer to build and consume much more RAM**. Depending on the constraints of your computing environment, this could be prohibitive.\n",
    "\n",
    "The `tf.dynamic_rnn` function will transform your RNNCell into a dynamically generated graph that passes the state, whatever that may be, from one time step to the next, and keeps track of the outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow API (`dynamic_rnn`)\n",
    "\n",
    "Above, we added every node for every timestep to the graph before execution. This is called “static” construction. We could also let Tensorflow dynamically create the graph at execution time, which can be more efficient. To do this, instead of using a list of tensors (of length `num_steps` and shape `[batch_size, features]`), we keep everything in a single 3-dimnesional tensor of shape `[batch_size, num_steps, features]`, and use Tensorflow’s `dynamic_rnn` function. This is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "Inputs\n",
    "\"\"\"\n",
    "\n",
    "rnn_inputs = tf.one_hot(x, num_classes)\n",
    "\n",
    "\"\"\"\n",
    "RNN\n",
    "\"\"\"\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\"\"\"\n",
    "\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = tf.reshape(\n",
    "            tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) + b,\n",
    "            [batch_size, num_steps, num_classes])\n",
    "predictions = tf.nn.softmax(logits)\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.6449662911891937\n",
      "Average loss at step 200 for last 250 steps: 0.5688766324520111\n",
      "Average loss at step 300 for last 250 steps: 0.5277942746877671\n",
      "Average loss at step 400 for last 250 steps: 0.5149962466955185\n",
      "Average loss at step 500 for last 250 steps: 0.5182683664560318\n",
      "Average loss at step 600 for last 250 steps: 0.5161534306406975\n",
      "Average loss at step 700 for last 250 steps: 0.5155144155025482\n",
      "Average loss at step 800 for last 250 steps: 0.514730055630207\n",
      "Average loss at step 900 for last 250 steps: 0.5167294222116471\n"
     ]
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating `dynamic_rnn` with `tf.scan`\n",
    "Scan is a higher-order function that takes a function $(f:(x_t,y_{t−1})↦y_t)$, a sequence ($[x_0,x_1…x_n]$) and an initial value ($y−1$) and returns a sequence ($[y_0,y_1…y_n]$) according to the rule: $y_t=f(x_t,y_{t−1}$). In Tensorflow, scan treats the first dimension of a Tensor as the sequence. Thus, if fed a Tensor of shape $[n, m, o]$ as the sequence, scan would unpack it into a sequence of n-tensors, each with shape $[m, o]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "#init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "Inputs\n",
    "\"\"\"\n",
    "\n",
    "rnn_inputs = tf.one_hot(x, num_classes) # shape=(200, 5, 2)\n",
    "\n",
    "\"\"\"\n",
    "RNN\n",
    "\"\"\"\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "\"\"\"\n",
    "tf.scan\n",
    "    Args:\n",
    "        fn: two arguments (1st same structure as initializer, 2nd the same as elems)\n",
    "        elems: sequence of tensors unpacked along their first dimension\n",
    "        initializer: initial value for the accumulator\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "cell.__call__\n",
    "    Args:\n",
    "        inputs: 2-D tensor with shape [batch_size, input_size]\n",
    "        state: 2-D Tensor with shape [batch_size, self.state_size].\n",
    "    Returns:\n",
    "        Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "\"\"\"\n",
    "init_state = cell.zero_state(batch_size, tf.float32)\n",
    "rnn_outputs, final_states = \\\n",
    "    tf.scan(lambda accum, elem: cell(elem, accum[1]), # call(inputs, state)\n",
    "            tf.transpose(rnn_inputs, [1,0,2]), # shape=(5, 200, 2)\n",
    "            initializer=(tf.zeros([batch_size, state_size]), init_state))\n",
    "# (shape=(5, 200, 4), shape=(5, 200, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to note is that scan produces rnn_outputs with shape `[num_steps, batch_size, state_size]`, whereas the dynamic_rnn produces rnn_outputs with shape `[batch_size, num_steps, state_size] `(the first two dimensions are switched). Dynamic_rnn has the flexibility to switch this behavior, using the `time_major` argument. `Tf.scan` does not have this flexibility, which is why we transpose `rnn_inputs` and `y` in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'scan/TensorArrayStack/TensorArrayGatherV3:0' shape=(5, 200, 4) dtype=float32>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "rnn_outputs = tf.transpose(rnn_outputs, [1, 0, 2]) # shape=(200, 5, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.reshape(\n",
    "            tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), W) + b,\n",
    "            [batch_size, num_steps, num_classes])\n",
    "predictions = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scan was only marginally slower than using `dynamic_rnn`, and gives us the flexibility and understanding to tweak the code if we ever need to (e.g., if for some reason we wanted to create a skip connection from the state at timestep `t-2` to timestep `t`, it would be easy to do with scan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upgrading the RNN cell\n",
    "\n",
    "We can seamlessly swap out the BasicRNNCell we were using for a Multi-layered LSTM cell. This was possible because the RNN cells conform to a general structure: every RNN cell is a function of the current input, $X_t$, and the prior state, $S_{t−1}$, that outputs a current state, $S_t$, and a current output, $Y_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.BasicRNNCell(state_size) # RNN\n",
    "cell = tf.nn.rnn_cell.LSTMCell(state_size) # LSTM\n",
    "cell = tf.nn.rnn_cell.GRUCell(state_size) # GRU\n",
    "\n",
    "num_layers = 5\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell( # Stacked LSTM\n",
    "    [tf.nn.rnn_cell.LSTMCell(state_size)] * num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
